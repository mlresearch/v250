---
title: Pretraining Vision-Language Model for Difference Visual Question Answering
  in Longitudinal Chest X-rays
abstract: Difference visual question answering (diff-VQA) is a challenging task that
  requires answering complex questions based on differences between a pair of images.
  This task is particularly important in reading chest X-ray images because radiologists
  often compare multiple images of the same patient taken at different times to track
  disease progression and changes in its severity in their clinical practice. However,
  previous works focused on designing specific network architectures for the diff-VQA
  task, missing opportunities to enhance the modelś performance using a pretrained
  vision-language model (VLM). Here, we introduce a novel VLM called PLURAL, which
  is pretrained on natural and longitudinal chest X-ray data for the diff-VQA task.
  The model is developed using a step-by-step approach, starting with being pretrained
  on natural images and texts, followed by being trained using longitudinal chest
  X-ray data. The longitudinal data consist of pairs of X-ray images, along with question-answer
  sets and radiologist’s reports that describe the changes in lung abnormalities and
  diseases over time. Our experimental results show that the PLURAL model outperforms
  state-of-the-art methods not only in diff-VQA for longitudinal X-rays but also in
  conventional VQA for a single X-ray image. Through extensive experiments, we demonstrate
  the effectiveness of the proposed VLM architecture and pretraining method in improving
  the model’s performance.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cho24a
month: 0
tex_title: Pretraining Vision-Language Model for Difference Visual Question Answering
  in Longitudinal Chest X-rays
firstpage: 263
lastpage: 275
page: 263-275
order: 263
cycles: false
bibtex_author: Cho, Yeongjae and Kim, Taehee and Shin, Heejun and Cho, Sungzoon and
  Shin, Dongmyung
author:
- given: Yeongjae
  family: Cho
- given: Taehee
  family: Kim
- given: Heejun
  family: Shin
- given: Sungzoon
  family: Cho
- given: Dongmyung
  family: Shin
date: 2024-12-23
address:
container-title: Proceedings of The 7nd International Conference on Medical Imaging
  with Deep Learning
volume: '250'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 12
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v250/main/assets/cho24a/cho24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
