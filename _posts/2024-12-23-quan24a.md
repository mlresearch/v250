---
title: 'Slide-SAM: Medical SAM Meets Sliding Window'
abstract: The Segment Anything Model (SAM) has achieved a notable success in two-dimensional
  image segmentation in natural images. However, the substantial gap between medical
  and natural images hinders its direct application to medical image segmentation
  tasks. Particularly in 3D medical images, SAM struggles to learn contextual relationships
  between slices, limiting its practical applicability. Moreover, applying 2D SAM
  to 3D images requires prompting the entire volume, which is time- and label-consuming.
  To address these problems, we propose Slide-SAM, which treats a stack of three adjacent
  slices as a prediction window. It firstly takes three slices from a 3D volume and
  point- or bounding box prompts on the central slice as inputs to predict segmentation
  masks for all three slices. Subsequently, the masks of the top and bottom slices
  are then used to generate new prompts for adjacent slices. Finally, step-wise prediction
  can be achieved by sliding the prediction window forward or backward through the
  entire volume. Our model is trained on multiple public and private medical datasets
  and demonstrates its effectiveness through extensive 3D segmetnation experiments,
  with the help of minimal prompts. Code is available at https://github.com/Curli-quan/Slide-SAM.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: quan24a
month: 0
tex_title: 'Slide-SAM: Medical SAM Meets Sliding Window'
firstpage: 1179
lastpage: 1195
page: 1179-1195
order: 1179
cycles: false
bibtex_author: Quan, Quan and Tang, Fenghe and Xu, Zikang and Zhu, Heqin and Zhou,
  S Kevin
author:
- given: Quan
  family: Quan
- given: Fenghe
  family: Tang
- given: Zikang
  family: Xu
- given: Heqin
  family: Zhu
- given: S Kevin
  family: Zhou
date: 2024-12-23
address:
container-title: Proceedings of The 7nd International Conference on Medical Imaging
  with Deep Learning
volume: '250'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 12
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v250/main/assets/quan24a/quan24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
